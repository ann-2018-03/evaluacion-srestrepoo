{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-spam.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "paLq7c4Nd4rl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "import re\n",
        "import seaborn as sns\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XVAroQR6d4rx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Read data"
      ]
    },
    {
      "metadata": {
        "id": "qG2POx_gd4r0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns = ['label', 'content'])\n",
        "folders = glob.glob(\"./datos/spam-filter/*\")\n",
        "for folder_aux in folders:\n",
        "    folder_name = folder_aux + \"/*\"\n",
        "    folder = glob.glob(folder_name)\n",
        "    for file in folder:\n",
        "        try:\n",
        "            with open(file, encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "        except UnicodeDecodeError:\n",
        "            with open(file, 'rb') as f:\n",
        "                content = f.read()\n",
        "        df = df.append({'label': 0 if 'ham' in folder_name else 1, \n",
        "                        'content': str(content).replace('\\\\n', '\\n')}, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZCv4EZe9d4r6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.to_csv(r'datos/spam-filter/dataFrame.csv')\n",
        "def remove_header(cols):\n",
        "    array_first = cols[1].replace('\\\\n', '\\n').split('\\n')\n",
        "    index_remove = 0\n",
        "    pattern = r'^[A-Za-z-]*: [a-zA-Z 0-9@.[\\]\\(\\)-]*'\n",
        "    for index, element in enumerate(array_first):\n",
        "        if re.search(pattern, element):\n",
        "            index_remove = index\n",
        "    return '\\n'.join(array_first[index_remove + 1:]).strip()\n",
        "\n",
        "def remove_tags_HTML(cols):\n",
        "    content = cols[1]\n",
        "    TAG_RE = re.compile(r'<[^>]+>')\n",
        "    TAG_REX = re.compile(r\"\\s+\")\n",
        "    content = TAG_RE.sub('', content)\n",
        "    content = TAG_REX.sub(' ', content)\n",
        "    return content\n",
        "\n",
        "def remove_spaces_tab(cols):\n",
        "    content = cols[1]\n",
        "    return content.replace(\"\\n\",\"\").strip(\"\\t\")\n",
        "\n",
        "def remove_web(cols):\n",
        "    content = cols[1]\n",
        "    TAG_RE = re.compile(r'https?:\\/\\/.*[\\n]*')\n",
        "    return TAG_RE.sub('', content)\n",
        "\n",
        "def remove_numbers(cols):\n",
        "    content = cols[1]\n",
        "    TAG_RE = re.compile(r'[0-9]*')\n",
        "    return TAG_RE.sub('', content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3qffZcjCd4sB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df['content'] = df.apply(remove_header, axis=1)\n",
        "df['content'] = df.apply(remove_tags_HTML, axis=1)\n",
        "df['content'] = df.apply(remove_spaces_tab, axis=1)\n",
        "df['content'] = df.apply(remove_numbers, axis=1)\n",
        "df['content'] = df.apply(remove_web, axis=1)\n",
        "X = df['content']\n",
        "y = df['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sguBjWiMd4sd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Procesamiento lenguaje"
      ]
    },
    {
      "metadata": {
        "id": "qBS6HURGd4sg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "def cleanText(message):   \n",
        "   \n",
        "    message = message.translate(str.maketrans('', '', string.punctuation))\n",
        "    words = [stemmer.stem(word) for word in message.split() if word.lower() not in stopwords.words(\"english\")]\n",
        "    return \" \".join(words)\n",
        "    \n",
        "X = list(map(cleanText, X))\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(X)\n",
        "X = X.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AdUM7FCMd4s9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Regresión Logística"
      ]
    },
    {
      "metadata": {
        "id": "PEW5QfVnd4tD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y=y.astype('int')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , stratify = y, test_size = 0.3,random_state=101)\n",
        "clf = LogisticRegression(solver='lbfgs')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ipbatIvdd4tS",
        "colab_type": "code",
        "outputId": "7c91d8ce-afb8-4353-8134-e4c322b7660b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9455026455026455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jQYVrC97d4tc",
        "colab_type": "code",
        "outputId": "d5a54279-034e-4579-a0f3-14040481bb5d",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96      1320\n",
            "           1       0.96      0.86      0.90       570\n",
            "\n",
            "   micro avg       0.95      0.95      0.95      1890\n",
            "   macro avg       0.95      0.92      0.93      1890\n",
            "weighted avg       0.95      0.95      0.94      1890\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f1LC7OZGd4tj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Clasificador con RN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "collapsed": true,
        "id": "pkFnVSJhgXMs",
        "outputId": "b64627bc-edd8-4ba1-bf25-7e21cc69d37d",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def grid_layers(capas):\n",
        "    param = []\n",
        "    for i in range(len(capas)):\n",
        "        classifier = Sequential()\n",
        "        classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu', input_dim = 60982))\n",
        "        for j in range(capas[i]-1):\n",
        "            classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "        classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "        classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "        classifier.fit(X_train, y_train, batch_size = 50, epochs = 30)\n",
        "        y_pred = classifier.predict(X_test)\n",
        "        y_pred = (y_pred > 0.5)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        param.append([classifier.summary(),cm,classifier.evaluate(X_test, y_test)])\n",
        "    return param\n",
        "layers = [2,5,8]\n",
        "resultado = grid_layers(layers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "4409/4409 [==============================] - 4s 921us/step - loss: 0.6744 - acc: 0.7419\n",
            "Epoch 2/30\n",
            "4409/4409 [==============================] - 4s 801us/step - loss: 0.4822 - acc: 0.9428\n",
            "Epoch 3/30\n",
            "4409/4409 [==============================] - 4s 801us/step - loss: 0.2597 - acc: 0.9698\n",
            "Epoch 4/30\n",
            "4409/4409 [==============================] - 4s 800us/step - loss: 0.1559 - acc: 0.9785\n",
            "Epoch 5/30\n",
            "4409/4409 [==============================] - 4s 802us/step - loss: 0.1072 - acc: 0.9844\n",
            "Epoch 6/30\n",
            "4409/4409 [==============================] - 4s 804us/step - loss: 0.0804 - acc: 0.9866\n",
            "Epoch 7/30\n",
            "4409/4409 [==============================] - 4s 805us/step - loss: 0.0638 - acc: 0.9873\n",
            "Epoch 8/30\n",
            "4409/4409 [==============================] - 4s 800us/step - loss: 0.0527 - acc: 0.9880\n",
            "Epoch 9/30\n",
            "4409/4409 [==============================] - 4s 803us/step - loss: 0.0449 - acc: 0.9896\n",
            "Epoch 10/30\n",
            "4409/4409 [==============================] - 4s 797us/step - loss: 0.0391 - acc: 0.9900\n",
            "Epoch 11/30\n",
            "4409/4409 [==============================] - 4s 798us/step - loss: 0.0348 - acc: 0.9907\n",
            "Epoch 12/30\n",
            "4409/4409 [==============================] - 4s 798us/step - loss: 0.0315 - acc: 0.9918\n",
            "Epoch 13/30\n",
            "4409/4409 [==============================] - 4s 795us/step - loss: 0.0288 - acc: 0.9923\n",
            "Epoch 14/30\n",
            "4409/4409 [==============================] - 4s 798us/step - loss: 0.0267 - acc: 0.9923\n",
            "Epoch 15/30\n",
            "4409/4409 [==============================] - 4s 803us/step - loss: 0.0250 - acc: 0.9925\n",
            "Epoch 16/30\n",
            "4409/4409 [==============================] - 4s 819us/step - loss: 0.0236 - acc: 0.9932\n",
            "Epoch 17/30\n",
            "4409/4409 [==============================] - 4s 798us/step - loss: 0.0224 - acc: 0.9934\n",
            "Epoch 18/30\n",
            "4409/4409 [==============================] - 4s 806us/step - loss: 0.0214 - acc: 0.9936\n",
            "Epoch 19/30\n",
            "4409/4409 [==============================] - 3s 792us/step - loss: 0.0205 - acc: 0.9939\n",
            "Epoch 20/30\n",
            "4409/4409 [==============================] - 4s 796us/step - loss: 0.0198 - acc: 0.9939\n",
            "Epoch 21/30\n",
            "4409/4409 [==============================] - 4s 796us/step - loss: 0.0190 - acc: 0.9941\n",
            "Epoch 22/30\n",
            "4409/4409 [==============================] - 3s 794us/step - loss: 0.0185 - acc: 0.9941\n",
            "Epoch 23/30\n",
            "4409/4409 [==============================] - 4s 797us/step - loss: 0.0179 - acc: 0.9941\n",
            "Epoch 24/30\n",
            "4409/4409 [==============================] - 4s 800us/step - loss: 0.0175 - acc: 0.9941\n",
            "Epoch 25/30\n",
            "4409/4409 [==============================] - 4s 806us/step - loss: 0.0171 - acc: 0.9946\n",
            "Epoch 26/30\n",
            "4409/4409 [==============================] - 4s 799us/step - loss: 0.0168 - acc: 0.9946\n",
            "Epoch 27/30\n",
            "4409/4409 [==============================] - 4s 798us/step - loss: 0.0163 - acc: 0.9946\n",
            "Epoch 28/30\n",
            "4409/4409 [==============================] - 4s 798us/step - loss: 0.0160 - acc: 0.9946\n",
            "Epoch 29/30\n",
            "4409/4409 [==============================] - 4s 801us/step - loss: 0.0158 - acc: 0.9946\n",
            "Epoch 30/30\n",
            "4409/4409 [==============================] - 4s 803us/step - loss: 0.0156 - acc: 0.9946\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_36 (Dense)             (None, 5)                 304915    \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 304,951\n",
            "Trainable params: 304,951\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1890/1890 [==============================] - 1s 668us/step\n",
            "Epoch 1/30\n",
            "4409/4409 [==============================] - 4s 957us/step - loss: 0.6847 - acc: 0.6983\n",
            "Epoch 2/30\n",
            "4409/4409 [==============================] - 4s 810us/step - loss: 0.6702 - acc: 0.6986\n",
            "Epoch 3/30\n",
            "4409/4409 [==============================] - 4s 816us/step - loss: 0.6582 - acc: 0.6986\n",
            "Epoch 4/30\n",
            "4409/4409 [==============================] - 4s 822us/step - loss: 0.6483 - acc: 0.6986\n",
            "Epoch 5/30\n",
            "4409/4409 [==============================] - 4s 816us/step - loss: 0.6403 - acc: 0.6986\n",
            "Epoch 6/30\n",
            "4409/4409 [==============================] - 4s 815us/step - loss: 0.6338 - acc: 0.6986\n",
            "Epoch 7/30\n",
            "4409/4409 [==============================] - 4s 818us/step - loss: 0.6287 - acc: 0.6986\n",
            "Epoch 8/30\n",
            "4409/4409 [==============================] - 4s 865us/step - loss: 0.6245 - acc: 0.6986\n",
            "Epoch 9/30\n",
            "4409/4409 [==============================] - 4s 873us/step - loss: 0.6214 - acc: 0.6986\n",
            "Epoch 10/30\n",
            "4409/4409 [==============================] - 4s 878us/step - loss: 0.6189 - acc: 0.6986\n",
            "Epoch 11/30\n",
            "4409/4409 [==============================] - 4s 852us/step - loss: 0.6170 - acc: 0.6986\n",
            "Epoch 12/30\n",
            "4409/4409 [==============================] - 4s 861us/step - loss: 0.6156 - acc: 0.6986\n",
            "Epoch 13/30\n",
            "4409/4409 [==============================] - 4s 835us/step - loss: 0.6146 - acc: 0.6986\n",
            "Epoch 14/30\n",
            "4409/4409 [==============================] - 4s 849us/step - loss: 0.6139 - acc: 0.6986\n",
            "Epoch 15/30\n",
            "4409/4409 [==============================] - 4s 858us/step - loss: 0.6133 - acc: 0.6986\n",
            "Epoch 16/30\n",
            "4409/4409 [==============================] - 4s 866us/step - loss: 0.6130 - acc: 0.6986\n",
            "Epoch 17/30\n",
            "4409/4409 [==============================] - 4s 864us/step - loss: 0.6127 - acc: 0.6986\n",
            "Epoch 18/30\n",
            "4409/4409 [==============================] - 4s 858us/step - loss: 0.6125 - acc: 0.6986\n",
            "Epoch 19/30\n",
            "4409/4409 [==============================] - 4s 855us/step - loss: 0.6124 - acc: 0.6986\n",
            "Epoch 20/30\n",
            "4409/4409 [==============================] - 4s 847us/step - loss: 0.6123 - acc: 0.6986\n",
            "Epoch 21/30\n",
            "4409/4409 [==============================] - 4s 850us/step - loss: 0.6122 - acc: 0.6986\n",
            "Epoch 22/30\n",
            "4409/4409 [==============================] - 4s 848us/step - loss: 0.6121 - acc: 0.6986\n",
            "Epoch 23/30\n",
            "4409/4409 [==============================] - 4s 854us/step - loss: 0.6121 - acc: 0.6986\n",
            "Epoch 24/30\n",
            "4409/4409 [==============================] - 4s 852us/step - loss: 0.6121 - acc: 0.6986\n",
            "Epoch 25/30\n",
            "4409/4409 [==============================] - 4s 848us/step - loss: 0.6121 - acc: 0.6986\n",
            "Epoch 26/30\n",
            "4409/4409 [==============================] - 4s 854us/step - loss: 0.6121 - acc: 0.6986\n",
            "Epoch 27/30\n",
            "4409/4409 [==============================] - 4s 862us/step - loss: 0.6121 - acc: 0.6986\n",
            "Epoch 28/30\n",
            "4409/4409 [==============================] - 4s 855us/step - loss: 0.6121 - acc: 0.6986\n",
            "Epoch 29/30\n",
            "4409/4409 [==============================] - 4s 866us/step - loss: 0.6121 - acc: 0.6986\n",
            "Epoch 30/30\n",
            "4409/4409 [==============================] - 4s 858us/step - loss: 0.6121 - acc: 0.6986\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_39 (Dense)             (None, 5)                 304915    \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 305,041\n",
            "Trainable params: 305,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1890/1890 [==============================] - 1s 733us/step\n",
            "Epoch 1/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.6846 - acc: 0.6986\n",
            "Epoch 2/30\n",
            "4409/4409 [==============================] - 4s 820us/step - loss: 0.6611 - acc: 0.6986\n",
            "Epoch 3/30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4409/4409 [==============================] - 4s 810us/step - loss: 0.6339 - acc: 0.6986\n",
            "Epoch 4/30\n",
            "4409/4409 [==============================] - 4s 841us/step - loss: 0.6172 - acc: 0.6986\n",
            "Epoch 5/30\n",
            "4409/4409 [==============================] - 4s 847us/step - loss: 0.6126 - acc: 0.6986\n",
            "Epoch 6/30\n",
            "4409/4409 [==============================] - 4s 834us/step - loss: 0.6121 - acc: 0.6986\n",
            "Epoch 7/30\n",
            "4409/4409 [==============================] - 4s 842us/step - loss: 0.6122 - acc: 0.6986\n",
            "Epoch 8/30\n",
            "4409/4409 [==============================] - 4s 833us/step - loss: 0.6122 - acc: 0.6986\n",
            "Epoch 9/30\n",
            "4409/4409 [==============================] - 4s 837us/step - loss: 0.6121 - acc: 0.6986\n",
            "Epoch 10/30\n",
            "4409/4409 [==============================] - 4s 831us/step - loss: 0.6122 - acc: 0.6986\n",
            "Epoch 11/30\n",
            "4409/4409 [==============================] - 4s 839us/step - loss: 0.6122 - acc: 0.6986\n",
            "Epoch 12/30\n",
            "4409/4409 [==============================] - 4s 984us/step - loss: 0.6122 - acc: 0.6986\n",
            "Epoch 13/30\n",
            "4409/4409 [==============================] - 4s 883us/step - loss: 0.6122 - acc: 0.6986\n",
            "Epoch 14/30\n",
            "4409/4409 [==============================] - 4s 847us/step - loss: 0.6122 - acc: 0.6986\n",
            "Epoch 15/30\n",
            "4409/4409 [==============================] - 4s 815us/step - loss: 0.6122 - acc: 0.6986\n",
            "Epoch 16/30\n",
            "4409/4409 [==============================] - 4s 810us/step - loss: 0.6121 - acc: 0.6986\n",
            "Epoch 17/30\n",
            "4409/4409 [==============================] - 4s 807us/step - loss: 0.6121 - acc: 0.6986\n",
            "Epoch 18/30\n",
            "4409/4409 [==============================] - 4s 809us/step - loss: 0.6121 - acc: 0.6986\n",
            "Epoch 19/30\n",
            "4409/4409 [==============================] - 4s 813us/step - loss: 0.6121 - acc: 0.6986\n",
            "Epoch 20/30\n",
            "4409/4409 [==============================] - 4s 811us/step - loss: 0.6121 - acc: 0.6986\n",
            "Epoch 21/30\n",
            "4409/4409 [==============================] - 4s 808us/step - loss: 0.6122 - acc: 0.6986\n",
            "Epoch 22/30\n",
            "4409/4409 [==============================] - 4s 816us/step - loss: 0.6121 - acc: 0.6986\n",
            "Epoch 23/30\n",
            "4409/4409 [==============================] - 4s 808us/step - loss: 0.6121 - acc: 0.6986\n",
            "Epoch 24/30\n",
            "4409/4409 [==============================] - 4s 821us/step - loss: 0.6122 - acc: 0.6986\n",
            "Epoch 25/30\n",
            "4409/4409 [==============================] - 4s 838us/step - loss: 0.6122 - acc: 0.6986\n",
            "Epoch 26/30\n",
            "4409/4409 [==============================] - 4s 816us/step - loss: 0.6122 - acc: 0.6986\n",
            "Epoch 27/30\n",
            "4409/4409 [==============================] - 4s 898us/step - loss: 0.6122 - acc: 0.6986\n",
            "Epoch 28/30\n",
            "4409/4409 [==============================] - 4s 988us/step - loss: 0.6122 - acc: 0.6986\n",
            "Epoch 29/30\n",
            "4409/4409 [==============================] - 4s 972us/step - loss: 0.6122 - acc: 0.6986\n",
            "Epoch 30/30\n",
            "4409/4409 [==============================] - 4s 981us/step - loss: 0.6122 - acc: 0.6986\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_45 (Dense)             (None, 5)                 304915    \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 305,131\n",
            "Trainable params: 305,131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1890/1890 [==============================] - 2s 801us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vuShxf64hVaI",
        "outputId": "4d704ab6-f3d6-4e3b-e5ef-029da6ccf0b0",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "cell_type": "code",
      "source": [
        "resultado\n",
        "# EL indicado es el #2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[None, array([[1290,   30],\n",
              "         [  59,  511]], dtype=int64), [0.1833308524856216,\n",
              "   0.9529100529100529]],\n",
              " [None, array([[1320,    0],\n",
              "         [ 570,    0]], dtype=int64), [0.612204247082352, 0.6984126984126984]],\n",
              " [None, array([[1320,    0],\n",
              "         [ 570,    0]], dtype=int64), [0.6122036979311989,\n",
              "   0.6984126984126984]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "DJFA6Q_Pd4uD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "precision = [i[2][1] for i in resultado]\n",
        "plt.bar([\"2 Capas\",\"5 Capas\",\"8 Capas\"],precision)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ophXa5p7jFpm",
        "outputId": "03bc943f-ab64-47da-e778-10963ea82d3a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def grid_neurons(neuronas):\n",
        "    param = [] \n",
        "    for i in range(len(neuronas)):\n",
        "        classifier = Sequential()\n",
        "        classifier.add(Dense(units = neuronas[i], kernel_initializer = 'uniform', activation = 'relu', input_dim = 60982))\n",
        "        classifier.add(Dense(units = neuronas[i], kernel_initializer = 'uniform', activation = 'relu'))\n",
        "        classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "        classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "        classifier.fit(X_train, y_train, batch_size = 32, epochs = 30)\n",
        "        y_pred = classifier.predict(X_test)\n",
        "        y_pred = (y_pred > 0.5)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        param.append([classifier.summary(),cm,classifier.evaluate(X_test, y_test)])\n",
        "    return param\n",
        "neurons = [8,16,32,64]\n",
        "resultado_neuronas = grid_neurons(neurons)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.5580 - acc: 0.6986\n",
            "Epoch 2/30\n",
            "4409/4409 [==============================] - 4s 950us/step - loss: 0.3134 - acc: 0.7954 0s - loss: 0.3172 - acc: 0.\n",
            "Epoch 3/30\n",
            "4409/4409 [==============================] - 4s 911us/step - loss: 0.1567 - acc: 0.9628\n",
            "Epoch 4/30\n",
            "4409/4409 [==============================] - 4s 909us/step - loss: 0.0827 - acc: 0.9782\n",
            "Epoch 5/30\n",
            "4409/4409 [==============================] - 4s 955us/step - loss: 0.0578 - acc: 0.9828\n",
            "Epoch 6/30\n",
            "4409/4409 [==============================] - 4s 957us/step - loss: 0.0441 - acc: 0.9866\n",
            "Epoch 7/30\n",
            "4409/4409 [==============================] - 4s 959us/step - loss: 0.0350 - acc: 0.9887 0s - loss: 0.0349 -\n",
            "Epoch 8/30\n",
            "4409/4409 [==============================] - 4s 960us/step - loss: 0.0293 - acc: 0.9912\n",
            "Epoch 9/30\n",
            "4409/4409 [==============================] - 4s 952us/step - loss: 0.0258 - acc: 0.9914 3s -\n",
            "Epoch 10/30\n",
            "4409/4409 [==============================] - 4s 922us/step - loss: 0.0231 - acc: 0.9921\n",
            "Epoch 11/30\n",
            "4409/4409 [==============================] - 4s 920us/step - loss: 0.0211 - acc: 0.9921\n",
            "Epoch 12/30\n",
            "4409/4409 [==============================] - 4s 920us/step - loss: 0.0195 - acc: 0.9934\n",
            "Epoch 13/30\n",
            "4409/4409 [==============================] - 4s 913us/step - loss: 0.0183 - acc: 0.9943\n",
            "Epoch 14/30\n",
            "4409/4409 [==============================] - 4s 907us/step - loss: 0.0174 - acc: 0.9943\n",
            "Epoch 15/30\n",
            "4409/4409 [==============================] - 4s 921us/step - loss: 0.0168 - acc: 0.9946\n",
            "Epoch 16/30\n",
            "4409/4409 [==============================] - 4s 918us/step - loss: 0.0161 - acc: 0.9946\n",
            "Epoch 17/30\n",
            "4409/4409 [==============================] - 4s 914us/step - loss: 0.0159 - acc: 0.9943\n",
            "Epoch 18/30\n",
            "4409/4409 [==============================] - 4s 920us/step - loss: 0.0152 - acc: 0.9946\n",
            "Epoch 19/30\n",
            "4409/4409 [==============================] - 4s 917us/step - loss: 0.0150 - acc: 0.9946\n",
            "Epoch 20/30\n",
            "4409/4409 [==============================] - 4s 914us/step - loss: 0.0147 - acc: 0.9946\n",
            "Epoch 21/30\n",
            "4409/4409 [==============================] - 4s 926us/step - loss: 0.0146 - acc: 0.9941\n",
            "Epoch 22/30\n",
            "4409/4409 [==============================] - 4s 916us/step - loss: 0.0144 - acc: 0.9946\n",
            "Epoch 23/30\n",
            "4409/4409 [==============================] - 4s 921us/step - loss: 0.0142 - acc: 0.9943\n",
            "Epoch 24/30\n",
            "4409/4409 [==============================] - 4s 923us/step - loss: 0.0142 - acc: 0.9943\n",
            "Epoch 25/30\n",
            "4409/4409 [==============================] - 4s 945us/step - loss: 0.0139 - acc: 0.9948\n",
            "Epoch 26/30\n",
            "4409/4409 [==============================] - 4s 969us/step - loss: 0.0139 - acc: 0.9943\n",
            "Epoch 27/30\n",
            "4409/4409 [==============================] - 4s 938us/step - loss: 0.0138 - acc: 0.9948\n",
            "Epoch 28/30\n",
            "4409/4409 [==============================] - 4s 946us/step - loss: 0.0137 - acc: 0.9948\n",
            "Epoch 29/30\n",
            "4409/4409 [==============================] - 4s 938us/step - loss: 0.0138 - acc: 0.9946\n",
            "Epoch 30/30\n",
            "4409/4409 [==============================] - 4s 1ms/step - loss: 0.0136 - acc: 0.9948\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_57 (Dense)             (None, 8)                 487864    \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 487,945\n",
            "Trainable params: 487,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1890/1890 [==============================] - 1s 742us/step\n",
            "Epoch 1/30\n",
            "4409/4409 [==============================] - 7s 2ms/step - loss: 0.4908 - acc: 0.8276\n",
            "Epoch 2/30\n",
            "4409/4409 [==============================] - 6s 1ms/step - loss: 0.1509 - acc: 0.9601\n",
            "Epoch 3/30\n",
            "4409/4409 [==============================] - 6s 1ms/step - loss: 0.0790 - acc: 0.9780\n",
            "Epoch 4/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0520 - acc: 0.9855\n",
            "Epoch 5/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0370 - acc: 0.9893\n",
            "Epoch 6/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0296 - acc: 0.9914\n",
            "Epoch 7/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0255 - acc: 0.9918\n",
            "Epoch 8/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0227 - acc: 0.9932\n",
            "Epoch 9/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0212 - acc: 0.9939\n",
            "Epoch 10/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0201 - acc: 0.9943\n",
            "Epoch 11/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0194 - acc: 0.9941\n",
            "Epoch 12/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0188 - acc: 0.9941\n",
            "Epoch 13/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0184 - acc: 0.9941\n",
            "Epoch 14/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0181 - acc: 0.9943\n",
            "Epoch 15/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0178 - acc: 0.9943\n",
            "Epoch 16/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0177 - acc: 0.9943\n",
            "Epoch 17/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0177 - acc: 0.9948\n",
            "Epoch 18/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0176 - acc: 0.9943\n",
            "Epoch 19/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0176 - acc: 0.9941\n",
            "Epoch 20/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0174 - acc: 0.9943\n",
            "Epoch 21/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0174 - acc: 0.9946\n",
            "Epoch 22/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0173 - acc: 0.9943\n",
            "Epoch 23/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0173 - acc: 0.9946\n",
            "Epoch 24/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0170 - acc: 0.9946\n",
            "Epoch 25/30\n",
            "4409/4409 [==============================] - 6s 1ms/step - loss: 0.0172 - acc: 0.9941\n",
            "Epoch 26/30\n",
            "4409/4409 [==============================] - 6s 1ms/step - loss: 0.0172 - acc: 0.9941\n",
            "Epoch 27/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0171 - acc: 0.9946\n",
            "Epoch 28/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0172 - acc: 0.9943\n",
            "Epoch 29/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0171 - acc: 0.9943\n",
            "Epoch 30/30\n",
            "4409/4409 [==============================] - 5s 1ms/step - loss: 0.0171 - acc: 0.9943\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_60 (Dense)             (None, 16)                975728    \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 976,017\n",
            "Trainable params: 976,017\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1890/1890 [==============================] - 1s 771us/step\n",
            "Epoch 1/30\n",
            "4409/4409 [==============================] - 10s 2ms/step - loss: 0.4128 - acc: 0.8521\n",
            "Epoch 2/30\n",
            "4409/4409 [==============================] - 9s 2ms/step - loss: 0.1083 - acc: 0.9682A: 0s - loss: 0.1100 - ac\n",
            "Epoch 3/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0653 - acc: 0.9837\n",
            "Epoch 4/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0456 - acc: 0.9887\n",
            "Epoch 5/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0376 - acc: 0.9909\n",
            "Epoch 6/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0330 - acc: 0.9916\n",
            "Epoch 7/30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0303 - acc: 0.9930A: 1\n",
            "Epoch 8/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0286 - acc: 0.9934\n",
            "Epoch 9/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0275 - acc: 0.9936\n",
            "Epoch 10/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0268 - acc: 0.9939\n",
            "Epoch 11/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0260 - acc: 0.9936\n",
            "Epoch 12/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0256 - acc: 0.9939\n",
            "Epoch 13/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0256 - acc: 0.9934\n",
            "Epoch 14/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0253 - acc: 0.9936\n",
            "Epoch 15/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0251 - acc: 0.9936\n",
            "Epoch 16/30\n",
            "4409/4409 [==============================] - 9s 2ms/step - loss: 0.0250 - acc: 0.9939\n",
            "Epoch 17/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0248 - acc: 0.9939\n",
            "Epoch 18/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0252 - acc: 0.9936\n",
            "Epoch 19/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0246 - acc: 0.9939\n",
            "Epoch 20/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0246 - acc: 0.9939\n",
            "Epoch 21/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0245 - acc: 0.9939\n",
            "Epoch 22/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0247 - acc: 0.9936\n",
            "Epoch 23/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0245 - acc: 0.9939\n",
            "Epoch 24/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0247 - acc: 0.9943\n",
            "Epoch 25/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0244 - acc: 0.9939\n",
            "Epoch 26/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0247 - acc: 0.9941\n",
            "Epoch 27/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0245 - acc: 0.9939\n",
            "Epoch 28/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0245 - acc: 0.9939\n",
            "Epoch 29/30\n",
            "4409/4409 [==============================] - 9s 2ms/step - loss: 0.0246 - acc: 0.9941\n",
            "Epoch 30/30\n",
            "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0245 - acc: 0.9939\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_63 (Dense)             (None, 32)                1951456   \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,952,545\n",
            "Trainable params: 1,952,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1890/1890 [==============================] - 2s 864us/step\n",
            "Epoch 1/30\n",
            "4409/4409 [==============================] - 15s 3ms/step - loss: 0.3689 - acc: 0.8576\n",
            "Epoch 2/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0940 - acc: 0.9721\n",
            "Epoch 3/30\n",
            "4409/4409 [==============================] - 14s 3ms/step - loss: 0.0510 - acc: 0.9882\n",
            "Epoch 4/30\n",
            "4409/4409 [==============================] - 14s 3ms/step - loss: 0.0369 - acc: 0.9914\n",
            "Epoch 5/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0325 - acc: 0.9927\n",
            "Epoch 6/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0306 - acc: 0.9936\n",
            "Epoch 7/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0304 - acc: 0.9930\n",
            "Epoch 8/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0295 - acc: 0.9936\n",
            "Epoch 9/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0297 - acc: 0.9934\n",
            "Epoch 10/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0290 - acc: 0.9934\n",
            "Epoch 11/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0290 - acc: 0.9936\n",
            "Epoch 12/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0284 - acc: 0.9939\n",
            "Epoch 13/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0284 - acc: 0.9939\n",
            "Epoch 14/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0286 - acc: 0.9939\n",
            "Epoch 15/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0290 - acc: 0.9934\n",
            "Epoch 16/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0285 - acc: 0.9936\n",
            "Epoch 17/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0289 - acc: 0.9934\n",
            "Epoch 18/30\n",
            "4409/4409 [==============================] - 14s 3ms/step - loss: 0.0288 - acc: 0.9936\n",
            "Epoch 19/30\n",
            "4409/4409 [==============================] - 14s 3ms/step - loss: 0.0294 - acc: 0.9934\n",
            "Epoch 20/30\n",
            "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0285 - acc: 0.9934\n",
            "Epoch 21/30\n",
            "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0288 - acc: 0.9936\n",
            "Epoch 22/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0284 - acc: 0.9936\n",
            "Epoch 23/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0285 - acc: 0.9934\n",
            "Epoch 24/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0284 - acc: 0.9934\n",
            "Epoch 25/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0285 - acc: 0.9936\n",
            "Epoch 26/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0288 - acc: 0.9932\n",
            "Epoch 27/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0283 - acc: 0.9939\n",
            "Epoch 28/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0286 - acc: 0.9934\n",
            "Epoch 29/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0282 - acc: 0.9932\n",
            "Epoch 30/30\n",
            "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0286 - acc: 0.9939\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_66 (Dense)             (None, 64)                3902912   \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 3,907,137\n",
            "Trainable params: 3,907,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1890/1890 [==============================] - 2s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bxPnBzABgXKV",
        "outputId": "40caf45b-28ed-465f-8b3d-76344f9a5bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "cell_type": "code",
      "source": [
        "resultado_neuronas"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[None, array([[1295,   25],\n",
              "         [  69,  501]], dtype=int64), [0.22836786856220065,\n",
              "   0.9502645502645503]],\n",
              " [None, array([[1292,   28],\n",
              "         [  62,  508]], dtype=int64), [0.25020826956652664,\n",
              "   0.9523809523809523]],\n",
              " [None, array([[1293,   27],\n",
              "         [  65,  505]], dtype=int64), [0.24309387730900198,\n",
              "   0.9513227513227513]],\n",
              " [None, array([[1289,   31],\n",
              "         [  67,  503]], dtype=int64), [0.2569881357933535,\n",
              "   0.9481481481481482]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XP8RiFR6YCit",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def regresor_base(optimizer,activation):\n",
        "    modelo = Sequential()\n",
        "    modelo.add(Dense(units = 8, kernel_initializer = 'uniform', activation = activation, input_dim = 60982))\n",
        "    modelo.add(Dropout(p = 0.1))\n",
        "    modelo.add(Dense(units = 8, kernel_initializer = 'uniform', activation = activation))\n",
        "    modelo.add(Dropout(p = 0.1))\n",
        "    modelo.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    modelo.compile(optimizer = optimizer, loss = 'binary_crossentropy' ,metrics = ['accuracy'])\n",
        "    return  modelo\n",
        "\n",
        "regresor = KerasClassifier(build_fn = regresor_base)\n",
        "parameters = {'batch_size': [5,10,20,50],\n",
        "              'epochs': [20,40,60,100],\n",
        "              'optimizer': ['adam'],\n",
        "              'activation':['sigmoid','relu']              \n",
        "             }\n",
        "\n",
        "## C.V\n",
        "grid_search = GridSearchCV(estimator = regresor,\n",
        "                           param_grid = parameters,\n",
        "                           cv=2\n",
        "                           )\n",
        "grid_search = grid_search.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4GXspW9v0ohj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hMeiCEZh-8Nj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**precisión del C.V de 91%**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YYPypgTnce5M",
        "outputId": "4d82642e-4c16-4b52-a45c-24d6ed6a9801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "cell_type": "code",
      "source": [
        "resultado_neuronas"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[None, array([[1295,   25],\n",
              "         [  69,  501]], dtype=int64), [0.22836786856220065,\n",
              "   0.9502645502645503]],\n",
              " [None, array([[1292,   28],\n",
              "         [  62,  508]], dtype=int64), [0.25020826956652664,\n",
              "   0.9523809523809523]],\n",
              " [None, array([[1293,   27],\n",
              "         [  65,  505]], dtype=int64), [0.24309387730900198,\n",
              "   0.9513227513227513]],\n",
              " [None, array([[1289,   31],\n",
              "         [  67,  503]], dtype=int64), [0.2569881357933535,\n",
              "   0.9481481481481482]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kJagQFYDccT8",
        "outputId": "f1c1759a-6f3e-46a6-e91d-4491762723c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "neurons"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8, 16, 32, 64]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4RTG7_WMgByI",
        "outputId": "b5c5f02a-45f5-456e-f41a-cd48a6dd33b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "cell_type": "code",
      "source": [
        "loss = [i[-1][0] for i in resultado_neuronas]\n",
        "precission = [i[-1][1] for i in resultado_neuronas]\n",
        "plt.plot(neurons, loss , '.-')\n",
        "plt.grid()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HDs5tFLgZyEA",
        "outputId": "fbbd8ce8-19f3-4e48-ff8f-1eaa1351f3ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(neurons, precission , '.-')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x22707cd44e0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "g9RYBHDO_d5n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Modelo final con hyper parametros ajustados**"
      ]
    },
    {
      "metadata": {
        "id": "Jq7Z7_dX_P05",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**PRECISIÓN MÁS ALTA ES EN 16 Y MÁS BAJA EN 8**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yfge7XEYX87N",
        "outputId": "7dac4532-60f1-4f3d-9b75-b4362879261a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5350
        }
      },
      "cell_type": "code",
      "source": [
        "classifier = Sequential()\n",
        "classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'sigmoid', input_dim = 60982))\n",
        "classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "es = EarlyStopping(monitor='loss', min_delta=1e-10, patience=5, verbose=1)\n",
        "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, verbose=1)\n",
        "classifier.fit(X_train, y_train, batch_size = 5, epochs = 100,callbacks=[es, rlr])\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4409/4409 [==============================] - 34s 8ms/step - loss: 0.4206 - acc: 0.7988\n",
            "Epoch 2/100\n",
            "4409/4409 [==============================] - 33s 7ms/step - loss: 0.1173 - acc: 0.9658\n",
            "Epoch 3/100\n",
            "4409/4409 [==============================] - 33s 8ms/step - loss: 0.0592 - acc: 0.9823\n",
            "Epoch 4/100\n",
            "4409/4409 [==============================] - 33s 7ms/step - loss: 0.0381 - acc: 0.9882\n",
            "Epoch 5/100\n",
            "4409/4409 [==============================] - 33s 8ms/step - loss: 0.0288 - acc: 0.9907\n",
            "Epoch 6/100\n",
            "4409/4409 [==============================] - 32s 7ms/step - loss: 0.0245 - acc: 0.9921\n",
            "Epoch 7/100\n",
            "4409/4409 [==============================] - 35s 8ms/step - loss: 0.0217 - acc: 0.9916\n",
            "Epoch 8/100\n",
            "4409/4409 [==============================] - 34s 8ms/step - loss: 0.0204 - acc: 0.9934\n",
            "Epoch 9/100\n",
            "4409/4409 [==============================] - 33s 8ms/step - loss: 0.0192 - acc: 0.9939\n",
            "Epoch 10/100\n",
            "4409/4409 [==============================] - 33s 7ms/step - loss: 0.0184 - acc: 0.9936\n",
            "Epoch 11/100\n",
            "4409/4409 [==============================] - 34s 8ms/step - loss: 0.0178 - acc: 0.9936\n",
            "Epoch 12/100\n",
            "4409/4409 [==============================] - 34s 8ms/step - loss: 0.0174 - acc: 0.9943\n",
            "Epoch 13/100\n",
            "4409/4409 [==============================] - 34s 8ms/step - loss: 0.0172 - acc: 0.9943\n",
            "Epoch 14/100\n",
            "4409/4409 [==============================] - 33s 8ms/step - loss: 0.0172 - acc: 0.9946\n",
            "Epoch 15/100\n",
            "4409/4409 [==============================] - 33s 8ms/step - loss: 0.0170 - acc: 0.9948\n",
            "Epoch 16/100\n",
            "4409/4409 [==============================] - 34s 8ms/step - loss: 0.0161 - acc: 0.9943\n",
            "Epoch 17/100\n",
            "4409/4409 [==============================] - 34s 8ms/step - loss: 0.0160 - acc: 0.9946\n",
            "Epoch 18/100\n",
            "4409/4409 [==============================] - 34s 8ms/step - loss: 0.0163 - acc: 0.9941\n",
            "Epoch 19/100\n",
            "4409/4409 [==============================] - 33s 7ms/step - loss: 0.0159 - acc: 0.9943\n",
            "Epoch 20/100\n",
            "4409/4409 [==============================] - 33s 8ms/step - loss: 0.0164 - acc: 0.9941\n",
            "Epoch 21/100\n",
            "4409/4409 [==============================] - 34s 8ms/step - loss: 0.0162 - acc: 0.9946\n",
            "Epoch 22/100\n",
            "4409/4409 [==============================] - 32s 7ms/step - loss: 0.0161 - acc: 0.9943\n",
            "Epoch 23/100\n",
            "4409/4409 [==============================] - 32s 7ms/step - loss: 0.0156 - acc: 0.9946\n",
            "Epoch 24/100\n",
            "4409/4409 [==============================] - 33s 7ms/step - loss: 0.0161 - acc: 0.9941\n",
            "Epoch 25/100\n",
            "4409/4409 [==============================] - 34s 8ms/step - loss: 0.0157 - acc: 0.9948\n",
            "Epoch 26/100\n",
            "4409/4409 [==============================] - 33s 8ms/step - loss: 0.0160 - acc: 0.9943\n",
            "Epoch 27/100\n",
            "4409/4409 [==============================] - 33s 8ms/step - loss: 0.0163 - acc: 0.9943\n",
            "Epoch 28/100\n",
            "4409/4409 [==============================] - 33s 8ms/step - loss: 0.0161 - acc: 0.9943\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 00028: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uS9VdFe578_I",
        "outputId": "c765ff0a-a4f1-4b50-8f7b-e8b3a4b0cb6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "classifier.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1890/1890 [==============================] - 2s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.21218291513890364, 0.9476190476190476]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZgT-1xiRXv9N",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# RESULTADO DE LA REGRESION\n",
        "\n",
        "    array([[1297,   23],\n",
        "           [  80,  490]]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}